{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf438eb0-7963-4966-9367-c8c65732efb7",
   "metadata": {},
   "source": [
    "## Sentiment classification - Using Bag of words\n",
    "\n",
    "### Train\n",
    "\n",
    "In this training metodology we'll compare the classification performance using bag of words and word embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc8264bf-b5af-4559-9e46-7cc52addfe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path of the folder 'resources' to the path from which we can import modules  \n",
    "import sys\n",
    "sys.path.append('../utilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa777c4-adc0-4870-b607-557894fa7323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nlp import BagOfWords, WordEmbedding\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca49b62-0240-49af-8131-8ff7249ea54a",
   "metadata": {},
   "source": [
    "### Read data\n",
    "\n",
    "In the following cell we read the data from a CSV file and filter only the GOOD / BAD evaluated texts (to simplify classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8b0b6c3-bf09-4710-9b8f-dc6e591b9297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bad</td>\n",
       "      <td>company company    lot  recalls barrons blog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bad</td>\n",
       "      <td>company company  risky   autonomous driving plan barrons blog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Good</td>\n",
       "      <td>company company plans ridehailing service  fleet  driverless cars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bad</td>\n",
       "      <td>company company files k  events f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Bad</td>\n",
       "      <td>company company  goldman sachs threw   towel barrons blog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Sentiment  \\\n",
       "0   0       Bad   \n",
       "2   2       Bad   \n",
       "3   3      Good   \n",
       "4   4       Bad   \n",
       "5   5       Bad   \n",
       "\n",
       "                                                                 Text  \n",
       "0                        company company    lot  recalls barrons blog  \n",
       "2       company company  risky   autonomous driving plan barrons blog  \n",
       "3  company company plans ridehailing service  fleet  driverless cars   \n",
       "4                                   company company files k  events f  \n",
       "5           company company  goldman sachs threw   towel barrons blog  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./sample_output/sentiment_train_processed1.csv\")\n",
    "\n",
    "text_field = \"Text\"\n",
    "class_field = \"Sentiment\"\n",
    "\n",
    "dataset = dataset.query(\"Sentiment != 'Neutral'\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01dbc8-826e-4997-81dd-a237dc187cb4",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "The bag of words representation is then calculated. Here we are using three diferent specificities, the regular bag of words, the TFIDF normalized one and the L2 normalized one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4f70f6-1661-4112-bae6-8f5a7949a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_model, word_counts             = BagOfWords.fit_regular_bow(dataset[text_field])\n",
    "tfidf_bow_model, tfidf_word_counts = BagOfWords.fit_tfidf_bow(dataset[text_field])\n",
    "norm_word_counts                   = BagOfWords.fit_normalized_bow(dataset[text_field])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f8761-4c87-4c4c-b07f-51c4cbd56aeb",
   "metadata": {},
   "source": [
    "### Classification\n",
    "Both of them will be tested as input to a Logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5927aad-73d1-48ff-bf59-3ede0798d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.model_selection as modsel\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, auc, roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a7346bd-968b-4864-80e1-db5c8118d64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bow</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.489575</td>\n",
       "      <td>0.657915</td>\n",
       "      <td>0.692664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.637066</td>\n",
       "      <td>0.661004</td>\n",
       "      <td>0.691892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.636293</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.687259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.647876</td>\n",
       "      <td>0.684170</td>\n",
       "      <td>0.694208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.658687</td>\n",
       "      <td>0.680309</td>\n",
       "      <td>0.695753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.664093</td>\n",
       "      <td>0.678764</td>\n",
       "      <td>0.690347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.664865</td>\n",
       "      <td>0.678764</td>\n",
       "      <td>0.691120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.665637</td>\n",
       "      <td>0.678764</td>\n",
       "      <td>0.691120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.667954</td>\n",
       "      <td>0.678764</td>\n",
       "      <td>0.691120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.671042</td>\n",
       "      <td>0.678764</td>\n",
       "      <td>0.691120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.669498</td>\n",
       "      <td>0.678764</td>\n",
       "      <td>0.690347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.668726</td>\n",
       "      <td>0.677992</td>\n",
       "      <td>0.691120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.671042</td>\n",
       "      <td>0.680309</td>\n",
       "      <td>0.698842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.672587</td>\n",
       "      <td>0.674903</td>\n",
       "      <td>0.696525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.673359</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.698069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.672587</td>\n",
       "      <td>0.669498</td>\n",
       "      <td>0.698069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.669498</td>\n",
       "      <td>0.700386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.668726</td>\n",
       "      <td>0.670270</td>\n",
       "      <td>0.699614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.669498</td>\n",
       "      <td>0.668726</td>\n",
       "      <td>0.697297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.670270</td>\n",
       "      <td>0.667954</td>\n",
       "      <td>0.696525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.668726</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.680309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.661004</td>\n",
       "      <td>0.668726</td>\n",
       "      <td>0.669498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bow     tfidf        l2\n",
       "0   0.489575  0.657915  0.692664\n",
       "1   0.637066  0.661004  0.691892\n",
       "2   0.636293  0.671815  0.687259\n",
       "3   0.647876  0.684170  0.694208\n",
       "4   0.658687  0.680309  0.695753\n",
       "5   0.664093  0.678764  0.690347\n",
       "6   0.664865  0.678764  0.691120\n",
       "7   0.665637  0.678764  0.691120\n",
       "8   0.667954  0.678764  0.691120\n",
       "9   0.671042  0.678764  0.691120\n",
       "10  0.669498  0.678764  0.690347\n",
       "11  0.668726  0.677992  0.691120\n",
       "12  0.671042  0.680309  0.698842\n",
       "13  0.672587  0.674903  0.696525\n",
       "14  0.673359  0.671815  0.698069\n",
       "15  0.672587  0.669498  0.698069\n",
       "16  0.671815  0.669498  0.700386\n",
       "17  0.668726  0.670270  0.699614\n",
       "18  0.669498  0.668726  0.697297\n",
       "19  0.670270  0.667954  0.696525\n",
       "20  0.668726  0.671815  0.680309\n",
       "21  0.661004  0.668726  0.669498"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=100000, penalty = \"l2\", fit_intercept=True, intercept_scaling=1000, class_weight='balanced')\n",
    "param_grid_ = {'C': [1e-5, 1e-4, 1e-3, 1e-2, 0.05, 0.1, 0.11, 0.12, 0.125, 0.15, 0.175, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1e0, 1e1, 1e2]}\n",
    "\n",
    "y = dataset[class_field]\n",
    "\n",
    "\n",
    "bow_search = modsel.GridSearchCV(\n",
    "    model,\n",
    "    cv=5,\n",
    "    param_grid=param_grid_,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "bow_search.fit(word_counts, y)\n",
    "\n",
    "\n",
    "l2_search = modsel.GridSearchCV(\n",
    "    model,\n",
    "    cv=5,\n",
    "    param_grid=param_grid_,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "l2_search.fit(norm_word_counts, y)\n",
    "\n",
    "\n",
    "tfidf_search = modsel.GridSearchCV(\n",
    "    model,\n",
    "    cv=5,\n",
    "    param_grid=param_grid_,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "tfidf_search.fit(tfidf_word_counts, y)\n",
    "\n",
    "\n",
    "Text_search_results = pd.DataFrame.from_dict({\n",
    "    'bow': bow_search.cv_results_['mean_test_score'],\n",
    "    'tfidf': tfidf_search.cv_results_['mean_test_score'],\n",
    "    'l2': l2_search.cv_results_['mean_test_score'],\n",
    "})\n",
    "\n",
    "Text_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "830f0744-b71c-4a32-9edb-7f0f094a464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = param_grid_['C'][13]\n",
    "\n",
    "Logistic_Model = LogisticRegression(\n",
    "    C=C,\n",
    "    fit_intercept=True,\n",
    "    penalty=\"l1\",\n",
    "    class_weight='balanced',\n",
    "    solver=\"liblinear\",\n",
    "    intercept_scaling=1000,\n",
    "    random_state=100000\n",
    ")\n",
    "\n",
    "log_CV = Logistic_Model.fit(tfidf_word_counts, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e29694-d4ea-4679-97c5-847df7da7f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6501930501930502"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_LASSO = modsel.cross_val_predict(log_CV, tfidf_word_counts, y, cv=5, method=\"predict\")\n",
    "preds_proba_LASSO = modsel.cross_val_predict(log_CV, tfidf_word_counts, y, cv=5, method=\"predict_proba\")\n",
    "\n",
    "accuracy_score(preds_LASSO, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b7904-138f-4e67-9b79-b78c8af29c7e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Our toy model obtained 65% of accuracy on the training data. That is not the best way to evaluate and select machine learning models but gives us a glimpse of how our data could be used for modeling.\n",
    "\n",
    "You can refer to **Gryphon classification template** to get more details of the process of fitting a model in this kind of problem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
